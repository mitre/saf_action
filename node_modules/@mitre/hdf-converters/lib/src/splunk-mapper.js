"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.SplunkMapper = exports.checkSplunkCredentials = exports.replaceKeyValueDescriptions = exports.consolidate_payloads = exports.map_hash = exports.group_by = void 0;
const splunk_sdk_no_env_1 = __importDefault(require("@mitre/splunk-sdk-no-env"));
const jquery_http_1 = __importDefault(require("@mitre/splunk-sdk-no-env/lib/platform/client/jquery_http"));
const lodash_1 = __importDefault(require("lodash"));
const global_1 = require("./utils/global");
const MAPPER_NAME = 'Splunk2HDF';
let logger = (0, global_1.createWinstonLogger)('Splunk2HDF');
function group_by(items, keyGetter) {
    const result = {};
    for (const i of items) {
        const key = keyGetter(i);
        const corrList = result[key];
        if (corrList) {
            corrList.push(i);
        }
        else {
            result[key] = [i];
        }
    }
    return result;
}
exports.group_by = group_by;
function map_hash(old, mapFunction) {
    const result = {};
    for (const key in old) {
        result[key] = mapFunction(old[key]);
    }
    return result;
}
exports.map_hash = map_hash;
function consolidate_payloads(payloads) {
    const grouped = group_by(payloads, (pl) => pl.meta.guid);
    const built = map_hash(grouped, consolidateFilePayloads);
    return Object.values(built);
}
exports.consolidate_payloads = consolidate_payloads;
function replaceKeyValueDescriptions(controls) {
    return controls.map((control) => {
        if (control.descriptions && !Array.isArray(control.descriptions)) {
            const extractedDescriptions = [];
            Object.entries(control.descriptions).forEach(([key, value]) => {
                extractedDescriptions.push({ label: key, data: value });
            });
            control.descriptions = extractedDescriptions;
        }
        return control;
    });
}
exports.replaceKeyValueDescriptions = replaceKeyValueDescriptions;
function consolidateFilePayloads(filePayloads) {
    var _a;
    const subtypes = group_by(filePayloads, (event) => event.meta.subtype);
    const execEvents = (subtypes['header'] ||
        []);
    const profileEvents = (subtypes['profile'] ||
        []);
    const controlEvents = (subtypes['control'] ||
        []);
    logger.debug(`Have ${execEvents.length} execution events`);
    logger.debug(`Have ${profileEvents.length} profile events`);
    logger.debug(`Have ${controlEvents.length} control events`);
    if (execEvents.length !== 1) {
        throw new Error(`Incorrect # of Evaluation events. Expected 1, got ${execEvents.length}`);
    }
    const exec = execEvents[0];
    (_a = exec.profiles) === null || _a === void 0 ? void 0 : _a.push(...profileEvents);
    const shaGroupedControls = group_by(controlEvents, (ctrl) => ctrl.meta.profile_sha256);
    for (const profile of profileEvents) {
        profile.controls = [];
        const sha = profile.meta.profile_sha256;
        logger.debug(`Adding controls for profile with SHA256: ${sha}`);
        const corrControls = shaGroupedControls[sha] || [];
        profile.controls.push(...replaceKeyValueDescriptions(corrControls));
        logger.debug(`Added ${profile.controls.length} controls to profile with SHA256 ${sha}`);
    }
    return exec;
}
async function checkSplunkCredentials(config, webCompatibility) {
    let service;
    if (webCompatibility) {
        service = new splunk_sdk_no_env_1.default.Service(new jquery_http_1.default.JQueryHttp(''), config);
    }
    else {
        service = new splunk_sdk_no_env_1.default.Service(config);
    }
    return new Promise((resolve, reject) => {
        setTimeout(() => reject(new Error('Login timed out. Please check your CORS configuration or validate you have inputted the correct domain')), 5000);
        service.login((error, result) => {
            try {
                if (error && error.status === 401) {
                    if (error.status === 401) {
                        reject('Incorrect Username or Password');
                    }
                    else if ('data' in error) {
                        reject(lodash_1.default.get(error, 'data.messages[0].text'));
                    }
                    reject(error);
                }
                else if (result) {
                    resolve(result);
                }
                reject(new Error('Failed to Login'));
            }
            catch (e) {
                reject(e);
            }
        });
    });
}
exports.checkSplunkCredentials = checkSplunkCredentials;
function unixTimeToDate(unixTime) {
    return new Date(parseFloat(unixTime) * 1000);
}
class SplunkMapper {
    constructor(config, webCompatibility = false, logService, loggingLevel) {
        this.config = config;
        this.webCompatibility = webCompatibility;
        if (logService) {
            logger = logService;
        }
        else {
            logger = (0, global_1.createWinstonLogger)(MAPPER_NAME, loggingLevel || 'debug');
        }
        logger.debug(`Initializing Splunk Client`);
        if (this.webCompatibility) {
            this.service = new splunk_sdk_no_env_1.default.Service(new jquery_http_1.default.JQueryHttp(''), config);
        }
        else {
            this.service = new splunk_sdk_no_env_1.default.Service(config);
        }
        logger.debug(`Initialized ${this.constructor.name} successfully`);
    }
    async createJob(query) {
        logger.debug(`Creating job for query: ${query}`);
        return new Promise((resolve, reject) => {
            this.service
                .jobs()
                .create(query, { exec_mode: 'blocking' }, (error, createdJob) => {
                if (error) {
                    reject(error);
                }
                else {
                    resolve(createdJob);
                }
            });
        });
    }
    parseSplunkResponse(query, results) {
        logger.info(`Got results for query: ${query}`);
        const objects = [];
        let rawDataIndex = results === null || results === void 0 ? void 0 : results.fields.findIndex((field) => field.toLowerCase() === '_raw');
        if (rawDataIndex === -1) {
            logger.error(`Field _raw not found, using default index 3`);
            rawDataIndex = 3;
        }
        logger.debug(`Got field _raw at index ${rawDataIndex}`);
        let indexTimeIndex = results === null || results === void 0 ? void 0 : results.fields.findIndex((field) => field.toLowerCase() === '_indextime');
        if (indexTimeIndex === -1) {
            logger.error(`Field _indextime not found, using default index 2`);
            indexTimeIndex = 2;
        }
        logger.debug(`Got field _indextime at index ${indexTimeIndex}`);
        logger.verbose(`Parsing data returned by Splunk and appending timestamps`);
        results.rows.forEach((value) => {
            let object;
            try {
                object = JSON.parse(value[rawDataIndex]);
            }
            catch {
                throw new Error('Unable to parse file. Have you configured EVENT_BREAKER? See https://github.com/mitre/saf/wiki/Splunk-Configuration');
            }
            try {
                lodash_1.default.set(object, 'meta.parse_time', unixTimeToDate(value[indexTimeIndex]).toISOString());
            }
            catch {
                lodash_1.default.set(object, 'meta.parse_time', new Date().toISOString());
            }
            objects.push(object);
        });
        logger.debug('Successfully parsed and added timestamps');
        return objects;
    }
    async queryData(query) {
        const job = await this.createJob(query);
        return new Promise((resolve, reject) => {
            job.track({}, {
                done: () => {
                    logger.debug(`Getting results for query: ${query}`);
                    job.results({ count: 100000 }, (err, results) => {
                        if (err) {
                            reject(err);
                        }
                        else {
                            try {
                                resolve(this.parseSplunkResponse(query, results));
                            }
                            catch (e) {
                                reject(e);
                            }
                        }
                    });
                }
            });
        });
    }
    async toHdf(guid) {
        logger.info(`Starting conversion of guid ${guid}`);
        return checkSplunkCredentials(this.config, this.webCompatibility)
            .then(async () => {
            logger.info(`Credentials valid, querying data for ${guid}`);
            const executionData = await this.queryData(`search index="*" meta.guid="${guid}"`);
            logger.info(`Data received, consolidating payloads for ${executionData.length} items`);
            return consolidate_payloads(executionData)[0];
        })
            .catch((error) => {
            throw error;
        });
    }
}
exports.SplunkMapper = SplunkMapper;
//# sourceMappingURL=splunk-mapper.js.map