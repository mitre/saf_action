"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const fs_1 = tslib_1.__importDefault(require("fs"));
const hdf_converters_1 = require("@mitre/hdf-converters");
const global_1 = require("../../utils/global");
const baseCommand_1 = require("../../utils/oclif/baseCommand");
class DBProtect2HDF extends baseCommand_1.BaseCommand {
    static usage = '<%= command.id %> -i <dbprotect-xml> -o <hdf-scan-results-json> [-h] [-w]';
    static description = 'Translate a DBProtect report in "Check Results Details" XML format into a Heimdall Data Format JSON file';
    static examples = [
        '<%= config.bin %> <%= command.id %> -i check_results_details_report.xml -o output-hdf-name.json',
    ];
    static flags = {
        input: core_1.Flags.string({
            char: 'i',
            required: true,
            description: "'Check Results Details' XML File",
        }),
        output: core_1.Flags.string({
            char: 'o',
            required: true,
            description: 'Output HDF JSON File',
        }),
        includeRaw: core_1.Flags.boolean({
            char: 'w',
            required: false,
            description: 'Include raw input file in HDF JSON file',
        }),
    };
    async run() {
        const { flags } = await this.parse(DBProtect2HDF);
        // Check for correct input type
        const data = fs_1.default.readFileSync(flags.input, 'utf8');
        (0, global_1.checkInput)({ data, filename: flags.input }, 'dbProtect', 'DBProtect report in "Check Results Details" XML format');
        const converter = new hdf_converters_1.DBProtectMapper(data, flags.includeRaw);
        fs_1.default.writeFileSync((0, global_1.checkSuffix)(flags.output), JSON.stringify(converter.toHdf(), null, 2));
    }
}
exports.default = DBProtect2HDF;
//# sourceMappingURL=dbprotect2hdf.js.map