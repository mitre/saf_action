"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const inspecjs_1 = require("inspecjs");
const lodash_1 = tslib_1.__importDefault(require("lodash"));
const fs_1 = tslib_1.__importDefault(require("fs"));
const objects_to_csv_1 = tslib_1.__importDefault(require("objects-to-csv"));
const csv_1 = require("../../utils/csv");
const global_1 = require("../../utils/global");
const baseCommand_1 = require("../../utils/oclif/baseCommand");
const path_1 = tslib_1.__importDefault(require("path"));
const colors_1 = tslib_1.__importDefault(require("colors")); // eslint-disable-line no-restricted-imports
const inquirer_1 = tslib_1.__importDefault(require("inquirer"));
const inquirer_file_tree_selection_prompt_1 = tslib_1.__importDefault(require("inquirer-file-tree-selection-prompt"));
const cliHelper_1 = require("../../utils/oclif/cliHelper");
const events_1 = require("events");
class HDF2CSV extends baseCommand_1.BaseCommand {
    static usage = '<%= command.id %> [-i <hdf-json>|--interactive] [-o <csv-file>|--interactive] ' +
        ' [-f <header-fields>|--interactive] [-t|--interactive] [-L info|warn|debug|verbose]';
    static description = 'Translate a Heimdall Data Format JSON file into a Comma Separated Values (CSV) file';
    static examples = [
        {
            description: '\x1B[93mRunning the CLI interactively\x1B[0m',
            command: '<%= config.bin %> <%= command.id %> --interactive',
        },
        {
            description: '\x1B[93mProviding flags at the command line\x1B[0m',
            command: '<%= config.bin %> <%= command.id %> -i rhel7-results.json -o rhel7.csv --fields "Results Set,Status,ID,Title,Severity"',
        },
    ];
    // eslint-disable-next-line no-warning-comments
    /*
      TODO: Find a way to make certain flags required when not using --interactive.
            In this CLI the -i and -o are required fields, but if required: is set
            to true, when using the --interactive the process will state that those
            fields are required. Currently we check the flags that are required
            programmatically when the --interactive is not used.
      The exclusive: ['interactive'] flag option is used to state that the flag
      cannot be specified alongside the --interactive flag
    */
    static flags = {
        input: core_1.Flags.string({
            char: 'i',
            required: false,
            exclusive: ['interactive'],
            description: '(required if not --interactive) Input HDF file'
        }),
        output: core_1.Flags.string({
            char: 'o',
            required: false,
            exclusive: ['interactive'],
            description: '(required if not --interactive) Output CSV file'
        }),
        fields: core_1.Flags.string({
            char: 'f',
            required: false,
            exclusive: ['interactive'],
            default: csv_1.csvExportFields.join(','),
            description: 'Fields to include in output CSV, separated by commas',
        }),
        noTruncate: core_1.Flags.boolean({
            char: 't',
            required: false,
            exclusive: ['interactive'],
            default: false,
            description: 'Do not truncate fields longer than 32,767 characters (the cell limit in Excel)'
        }),
    };
    async run() {
        const { flags } = await this.parse(HDF2CSV);
        (0, cliHelper_1.addToProcessLogData)('================== HDF2CSV CLI Process ===================');
        (0, cliHelper_1.addToProcessLogData)(`Date: ${new Date().toISOString()}\n`);
        let inputFile = '';
        let outputFile = '';
        let includeFields = '';
        let truncateFields = false;
        if (flags.interactive) {
            const interactiveFlags = await getFlags();
            inputFile = interactiveFlags.inputFile;
            outputFile = path_1.default.join(interactiveFlags.outputDirectory, interactiveFlags.outputFileName);
            includeFields = interactiveFlags.fields.join(',');
            truncateFields = Boolean(interactiveFlags.truncateFields);
        }
        else if (this.requiredFlagsProvided(flags)) {
            inputFile = flags.input;
            outputFile = flags.output;
            includeFields = flags.fields;
            truncateFields = flags.noTruncate;
            // Save the flags to the log object
            (0, cliHelper_1.addToProcessLogData)('Process Flags ============================================');
            for (const key in flags) {
                if (Object.prototype.hasOwnProperty.call(flags, key)) {
                    (0, cliHelper_1.addToProcessLogData)(key + '=' + flags[key]);
                }
            }
        }
        else {
            return;
        }
        if (validFileFlags(inputFile, outputFile)) {
            const contextualizedEvaluation = (0, inspecjs_1.contextualizeEvaluation)(JSON.parse(fs_1.default.readFileSync(inputFile, 'utf8')));
            // Convert all controls from a file to ControlSetRows
            let rows = convertRows(contextualizedEvaluation, (0, global_1.convertFullPathToFilename)(inputFile), includeFields.split(','));
            rows = rows.map((row, index) => {
                const cleanedRow = {};
                for (const key in row) {
                    if (row[key] !== undefined) {
                        if ((row[key]).length > 32767 && truncateFields) {
                            if ('ID' in row) {
                                console.error(`Field ${key} of control ${row.ID} is longer than 32,767 characters and has been truncated for compatibility with Excel. To disable this behavior use the option --noTruncate`);
                            }
                            else {
                                console.error(`Field ${key} of control at index ${index} is longer than 32,767 characters and has been truncated for compatibility with Excel. To disable this behavior use the option --noTruncate`);
                            }
                            cleanedRow[key] = lodash_1.default.truncate(row[key], { length: 32757, omission: 'TRUNCATED' });
                        }
                        else {
                            cleanedRow[key] = row[key];
                        }
                    }
                }
                return cleanedRow;
            });
            await new objects_to_csv_1.default(rows).toDisk(outputFile);
            (0, cliHelper_1.saveProcessLogData)();
        }
    }
    requiredFlagsProvided(flags) {
        let missingFlags = false;
        let strMsg = 'Warning: The following errors occurred:\n';
        if (!flags.input) {
            strMsg += colors_1.default.dim('  Missing required flag input (HDF file)\n');
            missingFlags = true;
        }
        if (!flags.output) {
            strMsg += colors_1.default.dim('  Missing required flag output (CSV file)\n');
            missingFlags = true;
        }
        if (missingFlags) {
            strMsg += 'See more help with -h or --help';
            this.warn(strMsg);
        }
        return !missingFlags;
    }
}
exports.default = HDF2CSV;
function convertRows(evaluation, filename, fieldsToAdd) {
    const controls = evaluation.contains.flatMap(profile => profile.contains) || [];
    return controls.map(ctrl => (0, csv_1.convertRow)(filename, ctrl, fieldsToAdd));
}
// Interactively ask the user for the arguments required for the cli.
// All flags, required and optional are asked
async function getFlags() {
    // The default max listeners is set to 10. The inquire checkbox sets a
    // listener for each entry it displays, we are providing 16 entries,
    // does using 16 listeners. Need to increase the defaultMaxListeners.
    events_1.EventEmitter.defaultMaxListeners = 20;
    inquirer_1.default.registerPrompt('file-tree-selection', inquirer_file_tree_selection_prompt_1.default);
    (0, cliHelper_1.printYellow)('Provide the necessary information:');
    (0, cliHelper_1.printGreen)('  Required flag - HDF file to convert to a CSV formatted file');
    (0, cliHelper_1.printGreen)('  Required flag - CSV output directory (output file name is hdf2csv.csv)');
    (0, cliHelper_1.printMagenta)('  Optional flag - Fields to include in output CSV (comma delineated)');
    (0, cliHelper_1.printMagenta)('  Optional flag - Truncate fields that exceed Excel cell limit (32,767 characters)\n');
    const choices = [];
    for (const str of csv_1.csvExportFields) {
        choices.push(str);
    }
    const questions = [
        {
            type: 'file-tree-selection',
            name: 'inputFile',
            message: 'Select the HDF file to be converted to a CSV:',
            filters: 'json',
            pageSize: 15,
            require: true,
            enableGoUpperDirectory: true,
            transformer: (input) => {
                const name = input.split(path_1.default.sep).pop();
                const fileExtension = name.split('.').slice(1).pop();
                if (name[0] === '.') {
                    return colors_1.default.grey(name);
                }
                if (fileExtension === 'json') {
                    return colors_1.default.green(name);
                }
                return name;
            },
            validate: (input) => {
                const name = input.split(path_1.default.sep).pop();
                const fileExtension = name.split('.').slice(1).pop();
                if (fileExtension !== 'json') {
                    return 'Not a .json file, please select another file';
                }
                return true;
            },
        },
        {
            type: 'file-tree-selection',
            name: 'outputDirectory',
            message: 'Select output directory for the generated CSV file:',
            pageSize: 15,
            require: true,
            onlyShowDir: true,
            enableGoUpperDirectory: true,
            transformer: (input) => {
                const name = input.split(path_1.default.sep).pop();
                if (name[0] === '.') {
                    return colors_1.default.grey(name);
                }
                return name;
            },
        },
        {
            type: 'input',
            name: 'outputFileName',
            message: 'Specify the output filename (.csv). It will be saved to the previously selected directory:',
            require: true,
            default() {
                return 'hdf2csv.csv';
            },
        },
        {
            type: 'checkbox',
            name: 'fields',
            message: 'Select fields to include in output CSV file:',
            choices,
            validate(answer) {
                if (answer.length === 0) {
                    return 'You must choose at least one field to include in the output.';
                }
                return true;
            },
        },
        {
            type: 'list',
            name: 'truncateFields',
            message: 'Truncate fields longer than 32,767 characters (the cell limit in Excel):',
            choices: ['true', 'false'],
            default: false,
            filter(val) {
                return (val === 'true');
            },
        },
    ];
    let interactiveValues;
    const ask = inquirer_1.default.prompt(questions).then((answers) => {
        (0, cliHelper_1.addToProcessLogData)('Process Flags ============================================');
        for (const envVar in answers) {
            if (answers[envVar] !== null) {
                (0, cliHelper_1.addToProcessLogData)(envVar + '=' + answers[envVar]);
            }
        }
        interactiveValues = answers;
    });
    await ask;
    return interactiveValues;
}
function validFileFlags(input, output) {
    // Do we have a file. Note that this check only ensures that a file was
    // provided, not necessary an HDF json file
    try {
        fs_1.default.lstatSync(input).isFile();
    }
    catch {
        throw new Error('Invalid or no HDF json file provided.');
    }
    // Here we simply check if the path leading to the provided output file is valid
    if (!fs_1.default.existsSync(path_1.default.dirname(output))) {
        throw new Error('Invalid output directory provided for the CSV output file.');
    }
    return true;
}
//# sourceMappingURL=hdf2csv.js.map