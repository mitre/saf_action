"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const fs_1 = tslib_1.__importDefault(require("fs"));
const hdf_converters_1 = require("@mitre/hdf-converters");
const global_1 = require("../../utils/global");
const baseCommand_1 = require("../../utils/oclif/baseCommand");
class Nikto2HDF extends baseCommand_1.BaseCommand {
    static usage = '<%= command.id %> -i <nikto-json> -o <hdf-scan-results-json> [-h] [-w]';
    static description = 'Translate a Nikto results JSON file into a Heimdall Data Format JSON file\n'
        + 'Note: Current this mapper only supports single target Nikto Scans';
    static examples = ['<%= config.bin %> <%= command.id %> -i nikto-results.json -o output-hdf-name.json'];
    static flags = {
        input: core_1.Flags.string({
            char: 'i',
            required: true,
            description: 'Input Niktop Results JSON File',
        }),
        output: core_1.Flags.string({
            char: 'o',
            required: true,
            description: 'Output HDF JSON File',
        }),
        includeRaw: core_1.Flags.boolean({
            char: 'w',
            required: false,
            description: 'Include raw input file in HDF JSON file',
        }),
    };
    async run() {
        const { flags } = await this.parse(Nikto2HDF);
        // Check for correct input type
        const data = fs_1.default.readFileSync(flags.input, 'utf8');
        (0, global_1.checkInput)({ data, filename: flags.input }, 'nikto', 'Nikto results JSON');
        const converter = new hdf_converters_1.NiktoMapper(data, flags.includeRaw);
        fs_1.default.writeFileSync((0, global_1.checkSuffix)(flags.output), JSON.stringify(converter.toHdf(), null, 2));
    }
}
exports.default = Nikto2HDF;
//# sourceMappingURL=nikto2hdf.js.map