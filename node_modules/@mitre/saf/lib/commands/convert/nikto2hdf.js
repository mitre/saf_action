"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const fs_1 = tslib_1.__importDefault(require("fs"));
const hdf_converters_1 = require("@mitre/hdf-converters");
const global_1 = require("../../utils/global");
class Nikto2HDF extends core_1.Command {
    async run() {
        const { flags } = await this.parse(Nikto2HDF);
        // Check for correct input type
        const data = fs_1.default.readFileSync(flags.input, 'utf8');
        (0, global_1.checkInput)({ data: data, filename: flags.input }, 'nikto', 'Nikto results JSON');
        const converter = new hdf_converters_1.NiktoMapper(data);
        fs_1.default.writeFileSync((0, global_1.checkSuffix)(flags.output), JSON.stringify(converter.toHdf()));
    }
}
Nikto2HDF.usage = 'convert nikto2hdf -i <nikto-json> -o <hdf-scan-results-json> [-h]';
Nikto2HDF.description = 'Translate a Nikto results JSON file into a Heimdall Data Format JSON file\nNote: Current this mapper only supports single target Nikto Scans';
Nikto2HDF.examples = ['saf convert nikto2hdf -i nikto-results.json -o output-hdf-name.json'];
Nikto2HDF.flags = {
    help: core_1.Flags.help({ char: 'h' }),
    input: core_1.Flags.string({ char: 'i', required: true, description: 'Input Niktop Results JSON File' }),
    output: core_1.Flags.string({ char: 'o', required: true, description: 'Output HDF JSON File' }),
};
exports.default = Nikto2HDF;
