"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const fs_1 = tslib_1.__importDefault(require("fs"));
const hdf_converters_1 = require("@mitre/hdf-converters");
const global_1 = require("../../utils/global");
class Netsparker2HDF extends core_1.Command {
    static usage = 'convert netsparker2hdf -i <netsparker-xml> -o <hdf-scan-results-json> [-h] [-w]';
    static description = 'Translate a Netsparker XML results file into a Heimdall Data Format JSON file\nThe current iteration only works with Netsparker Enterprise Vulnerabilities Scan.';
    static examples = ['saf convert netsparker2hdf -i netsparker_results.xml -o output-hdf-name.json'];
    static flags = {
        help: core_1.Flags.help({ char: 'h' }),
        input: core_1.Flags.string({ char: 'i', required: true, description: 'Input Netsparker XML File' }),
        output: core_1.Flags.string({ char: 'o', required: true, description: 'Output HDF JSON File' }),
        'with-raw': core_1.Flags.boolean({ char: 'w', required: false, description: 'Include raw input file in HDF JSON file' }),
    };
    async run() {
        const { flags } = await this.parse(Netsparker2HDF);
        // Check for correct input type
        const data = fs_1.default.readFileSync(flags.input, 'utf8');
        (0, global_1.checkInput)({ data, filename: flags.input }, 'netsparker', 'Netsparker XML results file');
        const converter = new hdf_converters_1.NetsparkerMapper(data, flags['with-raw']);
        fs_1.default.writeFileSync((0, global_1.checkSuffix)(flags.output), JSON.stringify(converter.toHdf(), null, 2));
    }
}
exports.default = Netsparker2HDF;
//# sourceMappingURL=netsparker2hdf.js.map