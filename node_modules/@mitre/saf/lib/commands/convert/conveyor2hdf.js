"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const fs_1 = tslib_1.__importDefault(require("fs"));
const hdf_converters_1 = require("@mitre/hdf-converters");
const global_1 = require("../../utils/global");
const path_1 = tslib_1.__importDefault(require("path"));
class Conveyor2HDF extends core_1.Command {
    static usage = 'convert conveyor2hdf -i <conveyor-json> -o <hdf-scan-results-json> [-h]';
    static description = 'Translate a Conveyor JSON file into a Heimdall Data Format JSON files';
    static examples = ['saf convert conveyor2hdf -i conveyor_results.json -o output-hdf-name.json'];
    static flags = {
        help: core_1.Flags.help({ char: 'h' }),
        input: core_1.Flags.string({ char: 'i', required: true, description: 'Input Conveyor JSON File' }),
        output: core_1.Flags.string({ char: 'o', required: true, description: 'Output HDF JSON Folder' }),
    };
    async run() {
        const { flags } = await this.parse(Conveyor2HDF);
        // Check for correct input type
        const data = fs_1.default.readFileSync(flags.input, 'utf8');
        (0, global_1.checkInput)({ data, filename: flags.input }, 'Conveyor', 'Conveyor JSON');
        const converter = new hdf_converters_1.ConveyorResults(data);
        const results = converter.toHdf();
        fs_1.default.mkdirSync(flags.output);
        for (const [filename, result] of Object.entries(results)) {
            fs_1.default.writeFileSync(path_1.default.join(flags.output, (0, global_1.checkSuffix)(filename)), JSON.stringify(result, null, 2));
        }
    }
}
exports.default = Conveyor2HDF;
//# sourceMappingURL=conveyor2hdf.js.map