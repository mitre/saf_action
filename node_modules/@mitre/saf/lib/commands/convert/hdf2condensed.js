"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const inspecjs_1 = require("inspecjs");
const fs_1 = tslib_1.__importDefault(require("fs"));
const threshold_1 = require("../../utils/threshold");
const lodash_1 = tslib_1.__importDefault(require("lodash"));
const global_1 = require("../../utils/global");
class HDF2Condensed extends core_1.Command {
    async run() {
        const { flags } = await this.parse(HDF2Condensed);
        const thresholds = {};
        const parsedExecJSON = (0, inspecjs_1.convertFileContextual)(fs_1.default.readFileSync(flags.input, 'utf8'));
        const parsedProfile = parsedExecJSON.contains[0];
        const overallStatusCounts = (0, threshold_1.extractStatusCounts)(parsedProfile);
        const overallCompliance = (0, threshold_1.calculateCompliance)(overallStatusCounts);
        lodash_1.default.set(thresholds, 'compliance', overallCompliance);
        // Severity counts
        for (const [severity, severityTargets] of Object.entries(threshold_1.severityTargetsObject)) {
            const severityStatusCounts = (0, threshold_1.extractStatusCounts)(parsedProfile, severity);
            for (const severityTarget of severityTargets) {
                const [statusName, _severity, thresholdType] = severityTarget.split('.');
                lodash_1.default.set(thresholds, severityTarget.replace(`.${thresholdType}`, ''), lodash_1.default.get(severityStatusCounts, (0, threshold_1.renameStatusName)(statusName)));
            }
        }
        // Total Counts
        for (const [type, counts] of Object.entries(thresholds)) {
            let total = 0;
            for (const [, count] of Object.entries(counts)) {
                total += count;
            }
            lodash_1.default.set(thresholds, `${type}.total`, total);
        }
        const result = {
            buckets: (0, threshold_1.extractControlSummariesBySeverity)(parsedProfile),
            status: thresholds,
        };
        fs_1.default.writeFileSync((0, global_1.checkSuffix)(flags.output), JSON.stringify(result));
    }
}
exports.default = HDF2Condensed;
HDF2Condensed.usage = 'hdf2condensed -i, --input=FILE -j, --json';
HDF2Condensed.description = 'Condensed format used by some community members to pre-process data for elasticsearch and custom dashboards';
HDF2Condensed.flags = {
    help: core_1.Flags.help({ char: 'h' }),
    input: core_1.Flags.string({ char: 'i', required: true, description: 'Input HDF file' }),
    output: core_1.Flags.string({ char: 'o', required: true, description: 'Output condensed JSON file' }),
};
HDF2Condensed.examples = ['saf convert hdf2condensed -i rhel7-results.json -o rhel7-condensed.json'];
